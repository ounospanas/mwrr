{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/adminis/anaconda3/envs/py36/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Permute, Reshape, Input,Concatenate,concatenate,dot,Reshape,add,multiply,maximum, Dot, Add, multiply\n",
    "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Conv1D, GlobalMaxPool2D, GlobalAveragePooling1D, Lambda, Input, Layer\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val.append(logs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'UCL' #PAMAP2\n",
    "set = 'test' #train\n",
    "modalities = 6 #18 for PAMAP2\n",
    "values = 128\n",
    "channels = 1\n",
    "nb_classes = 6 #12 for PAMAP2\n",
    "\n",
    "s_c = np.load(set+'_'+dataset+'_data.npy')\n",
    "s_q = np.load(set+'_'+dataset+'_questions.npy')\n",
    "y = np.load(set+'_'+dataset+'_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptionNet(input_shape):\n",
    "\n",
    "    input_acc = Input(shape=(modalities, values, channels))\n",
    "    x = Conv2D(32, (1, 11), padding='same')(input_acc)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 3))(x)\n",
    "    x = Dropout(0.50)(x)\n",
    "\n",
    "    z = Conv2D(48, (1, 11), padding='same')(x)\n",
    "    z = Activation('relu')(z)\n",
    "    z = MaxPooling2D(pool_size=(1, 3))(z)\n",
    "    z = Dropout(0.50)(z)\n",
    "    \n",
    "    y = Conv2D(64, (3, 11), padding='same')(z)\n",
    "    y = Activation('relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(1, 2))(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    return Model(input_acc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vects):\n",
    "    x, y = vects\n",
    "    eps = 1e-10\n",
    "    \n",
    "    sum_support = K.sum(K.square(y), 1, keepdims=True)\n",
    "    supportmagnitude = tf.rsqrt(tf.clip_by_value(sum_support, eps, float(\"inf\")))\n",
    "    \n",
    "    sum_query = K.sum(K.square(x), 1, keepdims=True)\n",
    "    querymagnitude = tf.rsqrt(tf.clip_by_value(sum_support, eps, float(\"inf\")))\n",
    "    \n",
    "    x_ = K.expand_dims(x,1)\n",
    "    y_ = K.expand_dims(y,2)\n",
    "    \n",
    "    dot_product = K.batch_dot(x_,y_)\n",
    "\n",
    "    dot_product = K.squeeze(dot_product,1)\n",
    "\n",
    "    \n",
    "    cosine_sim = dot_product*supportmagnitude#*querymagnitude\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchNet():\n",
    "    similarities = []\n",
    "\n",
    "    # network definition\n",
    "    input_shape = (modalities, values, channels)\n",
    "    perception = perceptionNet(input_shape)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    processed_a = perception(input_a)\n",
    "\n",
    "    input_b = Input(shape=(nb_classes, modalities, values, channels))\n",
    "\n",
    "    modelinputs = []\n",
    "    for lidx in range(nb_classes):\n",
    "        modelinputs.append(perception(Lambda(lambda x: x[:,lidx,:,:,:])(input_b)))\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "\n",
    "        sim = Lambda(cosine_similarity)([processed_a, modelinputs[i]])\n",
    "        similarities.append(sim)\n",
    "\n",
    "    similarities = Concatenate(axis=1)(similarities)\n",
    "    soft = Activation('softmax')(similarities)\n",
    "    \n",
    "    model = Model([input_a, input_b], soft)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303827751196172\n"
     ]
    }
   ],
   "source": [
    "accs_t = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    model = matchNet()\n",
    "    model.load_weights('trained_models/matchnet_UCL_'+str(i)+'.h5')\n",
    "    acc = np.mean(np.argmax(model.predict([s_q,s_c]),1)==y)\n",
    "    accs_t.append(acc)\n",
    "print(np.mean(accs_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptionNet(input_shape):\n",
    "\n",
    "    input_acc = Input(shape=(modalities, values, channels))\n",
    "    x = Conv2D(32, (1, 11), padding='same')(input_acc)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 3))(x)\n",
    "    x = Dropout(0.50)(x)\n",
    "\n",
    "    z = Conv2D(48, (1, 11), padding='same')(x)\n",
    "    z = Activation('relu')(z)\n",
    "    z = MaxPooling2D(pool_size=(1, 3))(z)\n",
    "    z = Dropout(0.50)(z)\n",
    "    \n",
    "    y = Conv2D(64, (1, 11), padding='same')(z)\n",
    "    y = Activation('relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(1, 2))(y)\n",
    "\n",
    "    return Model(input_acc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadDot(Layer):\n",
    "\n",
    "    def __init__(self, nb_head, size_per_head, **kwargs):\n",
    "        self.nb_head = nb_head\n",
    "        self.size_per_head = size_per_head\n",
    "        self.output_dim = nb_head * size_per_head\n",
    "        self.__name__ = 'MultiheadDot'\n",
    "        super(MultiheadDot, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.WQ = self.add_weight(name='WQ', \n",
    "                                  shape=(input_shape[0][-1], self.output_dim),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True)\n",
    "        self.WK = self.add_weight(name='WK', \n",
    "                                  shape=(input_shape[1][-1], self.output_dim),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True)\n",
    "        self.WV = self.add_weight(name='WV', \n",
    "                                  shape=(input_shape[2][-1], self.output_dim),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True)\n",
    "        \n",
    "        self.WA = self.add_weight(name='WA', \n",
    "                                  shape=(self.nb_head*self.size_per_head, 64),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True)\n",
    "        self.WE = self.add_weight(name='WE', \n",
    "                                  shape=(64, 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True)\n",
    "        \n",
    "        super(MultiheadDot, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        Q_in,K_in,V_in = x\n",
    "        \n",
    "        Q = K.dot(Q_in, self.WQ)\n",
    "        Q = K.reshape(Q, (-1, 6, 7, self.nb_head, self.size_per_head))\n",
    "        Q = K.permute_dimensions(Q, (0,3,1,2,4))\n",
    "        \n",
    "        Key = K.dot(K_in, self.WK)\n",
    "        Key = K.reshape(Key, (-1, 6, 7, self.nb_head, self.size_per_head))\n",
    "        Key = K.permute_dimensions(Key, (0,3,1,2,4))\n",
    "        \n",
    "        V = K.dot(V_in, self.WV)\n",
    "        V = K.reshape(V, (-1, 6, 7, self.nb_head, self.size_per_head))\n",
    "        V = K.permute_dimensions(V, (0,3,1,2,4))\n",
    "        \n",
    "        A = tf.keras.backend.batch_dot(Q, Key, axes=[4,4]) / self.size_per_head**0.5\n",
    "        A = K.softmax(A)\n",
    "        \n",
    "        E = tf.keras.backend.batch_dot(A, V, axes=[4,3])\n",
    "        E = K.permute_dimensions(E, (0,2,3,1,4))\n",
    "        E = K.reshape(E, (-1, 6*7, self.output_dim))\n",
    "        \n",
    "        sim = K.dot(E, self.WA)\n",
    "        sim = K.relu(sim)\n",
    "        sim = K.dropout(sim, 0.5)\n",
    "        sim = K.mean(sim, 1)\n",
    "        sim = K.dot(sim, self.WE)\n",
    "        \n",
    "        return [sim, A]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0][0], 1),(input_shape[0][0], 2, 6, 7, 7)]\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(MultiheadDot, self).get_config()\n",
    "        config.update({\"nb_head\": self.nb_head, \"size_per_head\":self.size_per_head})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_head = 3 # 2 for PAMAP2\n",
    "size_per_head = 64 # d variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "def relationalModule():\n",
    "    similarities = []\n",
    "    attentions = []\n",
    "    input_shape = (modalities, values, channels)\n",
    "\n",
    "    perception = perceptionNet(input_shape)\n",
    "    multihead = MultiheadDot(nb_head, size_per_head)\n",
    "    \n",
    "    config = multihead.get_config()\n",
    "    new_multihead = MultiheadDot.from_config(config)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    processed_a = perception(input_a)\n",
    "    flatten_a = Flatten()(processed_a)\n",
    "\n",
    "    input_b = Input(shape=(nb_classes, modalities, values, channels))\n",
    "\n",
    "    modelinputs = []\n",
    "    for lidx in range(nb_classes):\n",
    "        modelinputs.append(perception(Lambda(lambda x: x[:,lidx,:,:,:])(input_b)))\n",
    "\n",
    "    for i in range(nb_classes):\n",
    "        att, ma = new_multihead([processed_a, modelinputs[i], modelinputs[i]])\n",
    "        similarities.append(att)\n",
    "        attentions.append(ma)\n",
    "\n",
    "    similarities = Concatenate(axis=1)(similarities)\n",
    "    soft = Activation('softmax')(similarities)\n",
    "    \n",
    "    model = Model([input_a, input_b], soft)\n",
    "    \n",
    "    model_att = Model([input_a, input_b], attentions)\n",
    "    \n",
    "    return model, model_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9480861244019139\n"
     ]
    }
   ],
   "source": [
    "accs_t = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    \n",
    "    model,_ = relationalModule()\n",
    "    \n",
    "    model.load_weights('trained_models/relational_UCL_'+nb_head+'_'+size_per_head+'_'+str(i)+'.h5')\n",
    "    acc = np.mean(np.argmax(model.predict([s_q,s_c]),1)==y)\n",
    "    accs_t.append(acc)\n",
    "print(np.mean(accs_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
